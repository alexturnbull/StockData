{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf \n",
    "from datetime import date, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import os as os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/20 15:26:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "today = date.today()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName('Company_Project_1.0.1') \\\n",
    "        .config(\"spark.jars\", \"mariadb-java-client-3.1.4.jar\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS = spark.read.format(\"jdbc\")\\\n",
    "        .option(\"url\",\"jdbc:mariadb://localhost:3306/lnd\")\\\n",
    "        .option(\"driver\", \"org.mariadb.jdbc.Driver\")\\\n",
    "        .option(\"dbtable\", \"DOCS\")\\\n",
    "        .option(\"user\", \"ETL\")\\\n",
    "        .option(\"password\", 'Letmein2022!' )\\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DATE = DOCS.select(max(DOCS.Date)).alias('Max_Date').first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetStockData(stock, from_date):\n",
    "    #gets stock data from today back 14yrs. stock and date inputs should be strings and progress should be booleen\n",
    "    end_date = today.strftime(\"%Y-%m-%d\")\n",
    "    start_date = from_date\n",
    "    progress = False\n",
    "    stock_data = yf.download(stock, start_date, end_date, progress)\n",
    "    stock_data[\"Date\"] = stock_data.index\n",
    "    stock_data = stock_data [[\"Date\", \"Open\", \"High\", \"Low\", \"Close\",  \"Volume\"]]\n",
    "    stock_data.reset_index(drop=True, inplace=True)\n",
    "    stock_data = spark.createDataFrame(stock_data)\n",
    "    stock_data = stock_data.withColumn(\"Name\", lit(stock))\n",
    "    return stock_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "DOCS_DATA = GetStockData('DOCS', MAX_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+-------+----+\n",
      "|               Date|              Open|              High|               Low|             Close| Volume|Name|\n",
      "+-------------------+------------------+------------------+------------------+------------------+-------+----+\n",
      "|2023-10-05 00:00:00|21.270000457763672|21.489999771118164|21.170000076293945|  21.3700008392334|1096400|DOCS|\n",
      "|2023-10-06 00:00:00|21.200000762939453|22.075000762939453|21.200000762939453| 21.90999984741211|1676000|DOCS|\n",
      "|2023-10-09 00:00:00| 21.59000015258789|22.110000610351562|              21.5|21.889999389648438|1262800|DOCS|\n",
      "|2023-10-10 00:00:00|  21.8700008392334|22.700000762939453| 21.81999969482422| 22.40999984741211|1480300|DOCS|\n",
      "|2023-10-11 00:00:00|22.329999923706055|22.639999389648438|22.150999069213867|22.270000457763672|1499200|DOCS|\n",
      "|2023-10-12 00:00:00|22.280000686645508|22.280000686645508|21.420000076293945|21.670000076293945|1562100|DOCS|\n",
      "|2023-10-13 00:00:00|21.780000686645508|  21.8799991607666|21.389999389648438|21.600000381469727|2358000|DOCS|\n",
      "|2023-10-16 00:00:00|21.549999237060547|22.450000762939453|21.549999237060547|22.239999771118164|2775300|DOCS|\n",
      "|2023-10-17 00:00:00|22.059999465942383|            22.875|22.059999465942383|22.530000686645508|1530600|DOCS|\n",
      "|2023-10-18 00:00:00|22.469999313354492|22.559999465942383|21.985000610351562|22.030000686645508|1285900|DOCS|\n",
      "|2023-10-19 00:00:00|22.020000457763672|22.389999389648438|21.899999618530273|22.059999465942383|1027300|DOCS|\n",
      "+-------------------+------------------+------------------+------------------+------------------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DOCS_DATA.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_DATA.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"driver\", \"org.mariadb.jdbc.Driver\") \\\n",
    "    .option(\"url\", \"jdbc:mariadb://localhost:3306/lnd\") \\\n",
    "    .option(\"dbtable\", 'DOCS') \\\n",
    "    .option(\"user\", \"ETL\") \\\n",
    "    .option(\"password\", 'Letmein2022!') \\\n",
    "    .save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".companyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
